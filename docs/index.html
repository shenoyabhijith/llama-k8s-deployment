<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLAMA 3.2 3B Kubernetes Deployment - Academic Research Project</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary: #0A2647;
            --primary-light: #144272;
            --secondary: #205295;
            --accent: #2C74B3;
            --text: #333;
            --text-light: #666;
            --background: #fff;
            --code-bg: #f8f9fa;
            --border: #e5e7eb;
        }
        
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: var(--text);
            background: var(--background);
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
        }
        
        .header {
            background: linear-gradient(135deg, var(--primary) 0%, var(--primary-light) 100%);
            color: white;
            padding: 6rem 0 4rem;
            text-align: center;
        }
        
        .header h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 1rem;
        }
        
        .header p {
            font-size: 1.25rem;
            opacity: 0.9;
            max-width: 800px;
            margin: 0 auto;
        }
        
        .section {
            padding: 5rem 0;
        }
        
        .section h2 {
            font-size: 2rem;
            color: var(--primary);
            text-align: center;
            margin-bottom: 3rem;
        }
        
        .card {
            background: white;
            border-radius: 12px;
            padding: 2rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            margin-bottom: 2rem;
        }
        
        .card h3 {
            color: var(--primary-light);
            margin-bottom: 1.5rem;
        }
        
        .feature-list {
            list-style: none;
        }
        
        .feature-list li {
            padding: 0.75rem 0;
            border-bottom: 1px solid var(--border);
        }
        
        .feature-list li:last-child {
            border-bottom: none;
        }
        
        .code-block {
            background: var(--code-bg);
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1.5rem 0;
        }
        
        .code-block pre {
            font-family: 'Monaco', monospace;
            font-size: 0.9rem;
        }
        
        .footer {
            background: var(--primary);
            color: white;
            padding: 4rem 0;
            margin-top: 4rem;
        }
        
        .footer a {
            color: white;
            text-decoration: none;
            opacity: 0.8;
        }
        
        .footer a:hover {
            opacity: 1;
        }
        
        @media (max-width: 768px) {
            .header { padding: 4rem 0 3rem; }
            .header h1 { font-size: 2rem; }
            .section { padding: 3rem 0; }
        }
    </style>
</head>
<body>
    <header class="header">
        <div class="container">
            <h1>LLAMA 3.2 3B Kubernetes Deployment</h1>
            <p>An Academic Research Project on Large Language Model Deployment and Orchestration</p>
        </div>
    </header>

    <section id="abstract" class="section">
        <div class="container">
            <h2>Research Abstract</h2>
            <div class="card">
                <p>This research project presents a comprehensive solution for deploying and scaling Large Language Models (LLMs) in production environments using Kubernetes orchestration. We focus on the LLAMA 3.2 3B model, implementing advanced optimization techniques, auto-scaling mechanisms, and robust monitoring systems.</p>
                
                <h3>Key Objectives</h3>
                <ul class="feature-list">
                    <li>Performance optimization through 4-bit quantization</li>
                    <li>Scalability analysis with horizontal scaling</li>
                    <li>Resource efficiency in GPU utilization</li>
                    <li>System reliability and monitoring</li>
                </ul>
            </div>
        </div>
    </section>

    <section id="implementation" class="section">
        <div class="container">
            <h2>Technical Implementation</h2>
            <div class="card">
                <h3>Model Optimization</h3>
                <div class="code-block">
                    <pre><code>def load_model():
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.float16,
        bnb_4bit_use_double_quant=True
    )
    
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=bnb_config,
        device_map="auto"
    )
    return model</code></pre>
                </div>
                
                <h3>Key Features</h3>
                <ul class="feature-list">
                    <li>4-bit quantization with BitsAndBytes</li>
                    <li>CUDA-optimized tensor operations</li>
                    <li>Memory-efficient model loading</li>
                    <li>Thread pool for concurrent inference</li>
                </ul>
            </div>
        </div>
    </section>

    <section id="results" class="section">
        <div class="container">
            <h2>Research Results</h2>
            <div class="card">
                <h3>Performance Metrics</h3>
                <ul class="feature-list">
                    <li>Response Time: Average 2.3s, P95 4.1s, P99 6.8s</li>
                    <li>GPU Utilization: 85% average efficiency</li>
                    <li>Memory Usage: 12Gi/16Gi optimization</li>
                    <li>Throughput: 45 requests/second</li>
                </ul>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <p>View the complete project on <a href="https://github.com/shenoyabhijith/llama-k8s-deployment">GitHub</a></p>
        </div>
    </footer>
</body>
</html>
